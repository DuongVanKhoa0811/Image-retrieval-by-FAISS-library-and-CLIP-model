This github to index the features of image, which was retrieved by the CLIP model, and search for the text input

Run main.py to open the streamlit screen (streamlit run main.py)

Dataset: http://images.cocodataset.org/zips/val2017.zip 

'database.index': file index of the image
'Embedded_Files' folder contain the features of images (CLIP)
	You do not need that folder for running. That was used for the index process.